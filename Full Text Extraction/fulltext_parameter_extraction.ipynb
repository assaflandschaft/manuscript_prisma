{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40080416",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55231df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import langchain\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import logging\n",
    "import time\n",
    "import ast\n",
    "from typing import Optional\n",
    "from typing import Dict\n",
    "\n",
    "from langchain.chains.openai_functions import (\n",
    "    create_openai_fn_chain,\n",
    "    create_structured_output_chain,\n",
    ")\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4492b2b2",
   "metadata": {},
   "source": [
    "## Paths\n",
    "\n",
    "Set paths.\n",
    "\n",
    "**folder_path** : Path where all the pdf files exist.\n",
    "\n",
    "\n",
    "**chromadb_folder_path** : Path where you want chromadb indexes to be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a418d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = './FullTextArticles/'\n",
    "chromadb_folder_path = \"./chroma_db/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55b2885",
   "metadata": {},
   "source": [
    "## READ excel file\n",
    "\n",
    "Loading the excel file as a pandas dataframe with each row representing an article. We are setting row indices to refer to files more easily when manipulating the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "18ad6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('Articles_for_extraction.xlsx')\n",
    "\n",
    "df['index'] = range(1, len(df) + 1)\n",
    "df.set_index('index', inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6679521",
   "metadata": {},
   "source": [
    "## OpenAI model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa00be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_model_name='gpt-3.5-turbo'\n",
    "\n",
    "# openai_model_name = 'gpt-3.5-turbo-1106'\n",
    "\n",
    "#openai_model_name = 'gpt-4'\n",
    "\n",
    "#openai_model_name =\"gpt-4-32k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "827d8bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from dotenv import load_dotenv\n",
    "\n",
    "# load_dotenv()\n",
    "\n",
    "# os.environ['OPENAI_API_KEY'] = getpass.getpass('OpenAI API Key:')\n",
    "\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagram of the processing pipeline\n",
    "\n",
    "![pipeline_diagram.jpg](pipeline_diagram.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Loading Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs vs FullAbstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We operate with two types of documents:\n",
    "\n",
    "- **PDFs**: pdf documents of articles, located at `folder_path` set above\n",
    "- **FullAbstract**: a text copy of the abstract if there is no pdf for the corresponding articles\n",
    "\n",
    "The type of the document can be determined by referring to the dataframe.\n",
    "\n",
    "For **PDFs**, the `FullText` column will contain the name of the pdf file to be loaded and processed.\n",
    "\n",
    "For **FullAbstract** documents, the `FullText` column will contain the text `'Meeting Abstract'` and the `FullAbstract` column will contain the text of the actual abstract that is to be processed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Document loaders\n",
    "\n",
    "Documents are loaded via LangChain's document loaders, ensuring seamless access from PDFs or text columns. These loaders require an object of `Document` class, so for FullAbstract documents we will create objects using the following structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This pydantic class will be used for incorporating the text in FullAbstract column. Those text need to be of Document class to be processed by Langchain.\n",
    "\n",
    "class Document(BaseModel):\n",
    "    page_content: str\n",
    "    metadata: Dict[str, str]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual document loading will be taking place below, in the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Chunking and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a564e63",
   "metadata": {},
   "source": [
    "In the  chunking and embedding part of the process, we segment text into contextually meaningful chunks (1500-2000 characters), convert these chunks into vector embeddings for a nuanced contextual representation and store the embeddings in a Vector Storage.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single file processing\n",
    "\n",
    "For each row in our dataframe, we load the corresponding document, perform the chunking via RecursiveCharacterSplitter, use Chroma to convert the chunks into embeddings and then store the results in `chromadb_folder_path` under the name corresponding to the index of the row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52ce131",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_each_file(index, file, pdf=True, doc='' ):\n",
    "    \"\"\"Function to create chunking and embedding of a single document.\n",
    "\n",
    "    Parameters:\n",
    "    index (int): The index identifying the document in the pandas dataframe loaded above (excel file)\n",
    "    file (str): File path for pdf file of that specific document, or empty string if document is a FullAbstract\n",
    "    pdf (boolean): True, if the document at index in the pandas dataframe is a pdf, else False.\n",
    "    doc (str | dict) : Empty string if document is a pdf and a dictionary if document is a FullAbstract (see requirements\n",
    "                       for the dict structure in the text cell below)\n",
    "\n",
    "    Output:\n",
    "    Creates and saves the embeddings for that particular index inside the chromadb_folder_path.\n",
    "    For example, the data at index 1 in the pandas dataframe will be stored in \"./chroma_db/1/\" if the chromadb_folder_path\n",
    "    is set to chromadb_folder_path = \"./chroma_db/\"\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    if pdf:\n",
    "        # Load document from internal storage and split by pages\n",
    "        loader = PyPDFLoader(file)\n",
    "        pages = loader.load_and_split()\n",
    "    else:\n",
    "        # Create a single-page Document with the information from the 'doc' parameter\n",
    "        document_data = doc\n",
    "        pages = [Document(**document_data)]\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        # Set a really small chunk size, just to show.\n",
    "        chunk_size = 1200,\n",
    "        chunk_overlap  = 400,\n",
    "        length_function = len,\n",
    "    )\n",
    "\n",
    "    # Break down documents into chunks\n",
    "    all_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "\n",
    "    # Generate embeddings for each chunk and store them in the Vector Storage\n",
    "    vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings(), persist_directory= chromadb_folder_path + str(index))\n",
    "    print(f\"Embedded {index} Successfully\")\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on `doc` parameter\n",
    "\n",
    "As mentioned in Step 1 (Loading Documents), LangChain document loaders require a Document object. In order to load the information for FullAbstract documents in the correct format, `embed_each_file()` takes in the `doc` parameter, which is a python dictionary object of the following form\n",
    "\n",
    "    dict: {'page_content': 'String containing text version of FullAbstract document',\n",
    "           'metadata': {'source': 'Index of FullAbstract document in the pandas dataframe'}}\n",
    "\n",
    "This dictionary is used to create a Document class object that behaves the same way as the pdf files loaded via the LangChain loaders.\n",
    "\n",
    "PDFs do not need to have additional Document objects created, so if an article has a PDF file, the `doc` parameter is set to an empty string.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97d624a",
   "metadata": {},
   "source": [
    "#### Note on chunking parameters\n",
    "\n",
    "The `chunk_size` and `chunk_overlap` variables in the code above can be changed to better suit your model.\n",
    "\n",
    "gpt-3.5-turbo performs well for chunk_size 1000. [Source: https://eminent-crowberry-bb4.notion.site/Lex-GPT-74400b08f5f84cb5830baf2528f86b2f?pvs=4].\n",
    "\n",
    "If you're using gpt-4 we recommend you use `chunk size` more than 15000 and `chunk_overlap` between 1500-2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the whole dataframe\n",
    "\n",
    "In this part we iterate through the whole data frame line-by-line processing each document according to the procedure defined above in the 'Single file processing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d23f7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed_all():\n",
    "    \"\"\"Function used to embed all the documents in the dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    #If such a path exists, delete that path,\n",
    "    if os.path.exists(chromadb_folder_path):\n",
    "        shutil.rmtree(chromadb_folder_path)\n",
    "\n",
    "    # Each row represent an article\n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        print(f'Processing index number: {index}')\n",
    "\n",
    "        try:\n",
    "            if row['FullText'] == 'Meeting Abstract':\n",
    "                # Chunk only the abstract\n",
    "                doc = {\n",
    "                    'page_content': df.loc[index,'FullAbstract'],\n",
    "                    'metadata': {'source': f'{index}'}\n",
    "                }\n",
    "                embed_each_file(index, '', pdf=False, doc=doc)\n",
    "            else:\n",
    "                # Chunk the whole pdf file\n",
    "                file_path = folder_path + row['FullText']\n",
    "                embed_each_file(index, file_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'Error while reading index {index}', e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3549858d",
   "metadata": {},
   "source": [
    "### Embed all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d501021a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing index number: 1\n",
      "Embedded 1 Successfully\n",
      "Processing index number: 2\n",
      "Embedded 2 Successfully\n",
      "Processing index number: 3\n",
      "Embedded 3 Successfully\n",
      "Processing index number: 4\n",
      "Embedded 4 Successfully\n",
      "Processing index number: 5\n",
      "Embedded 5 Successfully\n",
      "Processing index number: 6\n",
      "Embedded 6 Successfully\n",
      "Processing index number: 7\n",
      "Embedded 7 Successfully\n",
      "Processing index number: 8\n",
      "Embedded 8 Successfully\n",
      "Processing index number: 9\n",
      "Embedded 9 Successfully\n",
      "Processing index number: 10\n",
      "Embedded 10 Successfully\n",
      "Processing index number: 11\n",
      "Embedded 11 Successfully\n",
      "Processing index number: 12\n",
      "Embedded 12 Successfully\n",
      "Processing index number: 13\n",
      "Embedded 13 Successfully\n",
      "Processing index number: 14\n",
      "Embedded 14 Successfully\n",
      "Processing index number: 15\n",
      "Embedded 15 Successfully\n",
      "Processing index number: 16\n",
      "Embedded 16 Successfully\n",
      "Processing index number: 17\n",
      "Embedded 17 Successfully\n",
      "Processing index number: 18\n",
      "Embedded 18 Successfully\n",
      "Processing index number: 19\n",
      "Embedded 19 Successfully\n",
      "Processing index number: 20\n",
      "Embedded 20 Successfully\n",
      "Processing index number: 21\n",
      "Embedded 21 Successfully\n",
      "Processing index number: 22\n",
      "Embedded 22 Successfully\n",
      "Processing index number: 23\n",
      "Embedded 23 Successfully\n",
      "Processing index number: 24\n",
      "Embedded 24 Successfully\n"
     ]
    }
   ],
   "source": [
    "embed_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3, Part 1: Retrieval, Multi-Query Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the process, we use a multi-query retriever technique to strategically retrieve relevant text from the vector storage.\n",
    "\n",
    "We use our LLM to divide each of the main questions into 3 sub-questions and aggregate everything in a multiple-question query collection. Later, in Step 3 Part 2, we will use the collection to query the Vector Storage, retrieve the `K` most relevant chunks per question and amalgamate the results to form the Full Context.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e1c471",
   "metadata": {},
   "source": [
    "## Question type and Schemas\n",
    "\n",
    "The variable **`question_types`** is a dictionary mapping each question type (a short string identifier for each question) to the actual text of the question that we ask to our LLM.\n",
    "\n",
    "whereas \n",
    "\n",
    "The variable **`schemas`** contains specifications of the **output** that we want for each question. An example of the specification would be requiring certain structures or data types, such as 'list of dictionary', 'Integer' or 'String'.\n",
    "\n",
    "**NOTE: the key in `question_types` and `schemas` should always match**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ccd5557",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_types = {\n",
    "    \"review\": \"Identify and determine if the manuscript under consideration is a review or meta-analysis article.\",\n",
    "    \"llm\" : \"Assess if one or several large language model (LLMs) are components within the patient-trial matching system.\",\n",
    "    \"llm_name\": \"Extract and list all large language models that are mentioned as components within the patient-trial matching system.\",\n",
    "    \"structured_data\":\"Assess if the patient-trial matching system incorporate structured data from the electronic health record system?\",\n",
    "\n",
    "    \"list_of_medical_conditions\" : \"Extract and list all medical conditions or diseases referenced within the text related to the clinical trials.\",\n",
    "    \"evaluate_patient_trial\" : \"Evaluate the patient-trial matching system described in the paper and assess if it positively impacted the diversity of subjects participating in the trial. Provide a concise textual assessment, detailing whether the system contributed to enhancing the diversity of subjects or not.\"  \n",
    "}\n",
    "\n",
    "schemas = {\n",
    "    \"review\": [\n",
    "        ResponseSchema(name=\"answer\", description=\"output should be in YES or NO\"),\n",
    "    ],\n",
    "    \"llm\": [\n",
    "        ResponseSchema(name=\"answer\", description=\"output should be in YES or NO\"),\n",
    "    ],\n",
    "    \"llm_name\": [\n",
    "        ResponseSchema(\n",
    "            name=\"answer\",\n",
    "            description=\"output this in python list i.e [] of DISTINCT comma separated strings. Leave empty list i.e [] if the information is missing.\",\n",
    "        ),\n",
    "    ],\n",
    "    \"structured_data\": [\n",
    "        ResponseSchema(name=\"answer\", description=\"output should be in YES or NO\"),\n",
    "    ],\n",
    "    \"list_of_medical_conditions\": [\n",
    "        ResponseSchema(\n",
    "            name=\"answer\",\n",
    "            description=\"output this in python list i.e [] of DISTINCT comma separated strings. Leave empty list i.e [] if the information is missing.\",\n",
    "        )\n",
    "    ],\n",
    "    \"evaluate_patient_trial\": [\n",
    "        ResponseSchema(\n",
    "            name=\"answer\", description=\"output this in a detailed text format\"\n",
    "        )\n",
    "    ],\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d5b196",
   "metadata": {},
   "source": [
    "## Generating multiple sub-questions from each question\n",
    "\n",
    "The function **`generate_multiple_queries(question, max_results)`** generates multiple version of a question. The reason for generating multiple sub-questions is beacause while retrieving context, using only one query may not be sufficient to retrieve relevant context that we pass to the LLM.\n",
    "\n",
    "Another reason for generating multiple sub-questions is because a specific question may sometimes be a combination of multiple question, it would be easier if we could break down that question into multiple sub-questions.\n",
    "\n",
    "\n",
    "For example:\n",
    "\n",
    "    Extract the number of patients participating in each trial discussed within the paper.\n",
    "\n",
    "This question can be a combination of two sub-questions.\n",
    "\n",
    "        1. The number of patients\n",
    "        2. The trials discussed in the paper.\n",
    "\n",
    "\n",
    "**By generating multiple sub-questions like above, we can use those to retrieve relevant chunks from our index for each sub-question and combine all the chunks in one place, forming the FullContext. So, the Full Context represents the information from index that is most relevant to answer the original question and will be passed to the LLM (gpt-3.5-turbo or gpt-4) instead of the entire index datafile, which also contains less-relevant information. The LLM will then be asked to use the FullContext to generate an accurate answer for the original question. So, the main thing to notice here, is that we use multiple queries of sub-questions to retrieve chunks from our index but we use only the original main question that is defined in `question_types` list to ask the LLM.**\n",
    "\n",
    "To understand more deeply, please refer to the diagram of the processing pipeline at the beginning of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c2e891f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_queries(question, max_results):\n",
    "    \"\"\" Function that generates multiple versions of a question.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): The original question to generate multiple questions for.\n",
    "    max_results (int): The number of questions to generate\n",
    "\n",
    "\n",
    "    Returns:\n",
    "    str: List of generated questions, formatted as an AST\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample Prompt for generating multiple quesitons\n",
    "    sample = \"\"\"You will be given a question. That question can be a complex question or it can be combination of\n",
    "    more than one questions. Your task is to decompose that question into {max_results} different questions {format_instructions}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    \"You are a helpful assistant that does tasks faithfully described to you.\"\n",
    "                )\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(sample),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #We've used gpt for generating multiple questions.\n",
    "    llm = ChatOpenAI(model_name= openai_model_name)\n",
    "\n",
    "    #define the output structure\n",
    "    schema = [\n",
    "        ResponseSchema(\n",
    "            name=\"answer\",\n",
    "            description=\"output should be in list of string format for example: ['query1','query2','query3'] \",\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    #format the prompt\n",
    "    output_parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "    format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "    #Get the response from LLM\n",
    "    answer = llm(\n",
    "        template.format_messages(\n",
    "            max_results=max_results,\n",
    "            question=question,\n",
    "            format_instructions=format_instructions,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        #Parse the JSON output from the LLM\n",
    "        final_ans = str(output_parser.parse(answer.content)[\"answer\"])\n",
    "\n",
    "    except:\n",
    "        final_ans = str(answer.content)\n",
    "\n",
    "    return final_ans\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90936bea",
   "metadata": {},
   "source": [
    "The code below generates multiple sub-questions for each question in `question_types` list.\n",
    "\n",
    "**NOTE: Our original question is also included at the end of each sub-question list so that we don't miss out quering using our original question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a75c854d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating Multiple Question for:  review\n",
      "Generating Multiple Question for:  llm\n",
      "Generating Multiple Question for:  llm_name\n",
      "Generating Multiple Question for:  structured_data\n",
      "Generating Multiple Question for:  list_of_medical_conditions\n",
      "Generating Multiple Question for:  evaluate_patient_trial\n"
     ]
    }
   ],
   "source": [
    "query_collection = {}\n",
    "for key,value in question_types.items():\n",
    "    print('Generating Multiple Question for: ', key)\n",
    "    query_collection[key] = ast.literal_eval(generate_multiple_queries(value, 3)) + [value]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**NOTE: We have already generated multiple sub-questions for each question below and saved it in a dictionary called `query_collection`. You may run the code below, if you want to generate multiple sub-questions yourself or you can just execute the code cell below this code cell.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6f802e2-7d40-465f-ae47-76bc0be9ab84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'review': ['What type of manuscript is under consideration?',\n",
       "  'Does the manuscript meet the criteria for a review article?',\n",
       "  'Does the manuscript meet the criteria for a meta-analysis article?',\n",
       "  'Identify and determine if the manuscript under consideration is a review or meta-analysis article.'],\n",
       " 'llm': ['What is the structure of the patient-trial matching system?',\n",
       "  'Are there any large language models incorporated in the patient-trial matching system?',\n",
       "  'If yes, how many large language models are used and what are their roles in the system?',\n",
       "  'Assess if one or several large language model (LLMs) are components within the patient-trial matching system.'],\n",
       " 'llm_name': ['What are large language models?',\n",
       "  'What components are mentioned within the patient-trial matching system?',\n",
       "  'Among those components, which are large language models?',\n",
       "  'Extract and list all large language models that are mentioned as components within the patient-trial matching system.'],\n",
       " 'structured_data': ['Does the patient-trial matching system utilize structured data?',\n",
       "  'Is the structured data used in the patient-trial matching system sourced from the electronic health record system?',\n",
       "  'Is the integration between the patient-trial matching system and the electronic health record system effective in incorporating structured data?',\n",
       "  'Assess if the patient-trial matching system incorporate structured data from the electronic health record system?'],\n",
       " 'list_of_medical_conditions': ['What are the medical conditions or diseases mentioned within the text?',\n",
       "  'Which of these conditions or diseases are specifically related to the clinical trials described in the text?',\n",
       "  'Can we list all these medical conditions or diseases?',\n",
       "  'Extract and list all medical conditions or diseases referenced within the text related to the clinical trials.'],\n",
       " 'evaluate_patient_trial': ['What is the patient-trial matching system described in the paper?',\n",
       "  'Did the system have a positive impact on the diversity of subjects participating in the trial?',\n",
       "  'Did the system contribute to enhancing the diversity of subjects in the trial?',\n",
       "  'Evaluate the patient-trial matching system described in the paper and assess if it positively impacted the diversity of subjects participating in the trial. Provide a concise textual assessment, detailing whether the system contributed to enhancing the diversity of subjects or not.']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2aa16105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These were the sub-questions generated initially when I ran the cell above. I've saved them in a dictionary so that we don't need to generate multiple sub-questions each time.\n",
    "\n",
    "query_collection = {\n",
    "    'review': [\n",
    "         'What is the definition of a review article?',\n",
    "         'What is the definition of a meta-analysis article?',\n",
    "         'What are the key characteristics of the manuscript under consideration?',\n",
    "         'Identify and determine if the manuscript under consideration is categorized as a review or meta-analysis article.'],\n",
    "     'llm': [\n",
    "        'Does the text mention large language models?',\n",
    "        'Are there any indications in the text that large language models are being used in the system being described?',\n",
    "        'Does the text provide any context or details about the use of large language models in the system?',\n",
    "        'Assess from the text if large language models are part of the system that the text describes.'],\n",
    "    'llm_name': [\n",
    "        'What are the large language models mentioned in the text?',\n",
    "        'Which large language models are identified as components within the system?',\n",
    "        'Are any of these models specifically used for patient matching in clinical trials?',\n",
    "        'Extract and list all large language models that are specifically mentioned or identified as components within the system described in the text related to patient matching for clinical trials.'],\n",
    "    'structured_data': [\n",
    "        'What is the patient-trial matching system described in the text?',\n",
    "        'Does the patient-trial matching system incorporate structured data as part of its input?',\n",
    "        'What type of non-textual data does the system incorporate, if any?',\n",
    "        'Analyze the text to determine if the patient-trial matching system described incorporates structured data (non-textual) as part of its input.'],\n",
    "    'list_of_medical_conditions': [\n",
    "        'What are all the medical conditions or diseases mentioned in the text?',\n",
    "        'Which of these conditions or diseases are related to clinical trials?',\n",
    "        'Which of these conditions or diseases are unique?',\n",
    "        'Extract and list all unique medical conditions or diseases referenced within the text related to the clinical trials.'],\n",
    "    'evaluate_patient_trial': [\n",
    "        'What is the patient-trial matching system described in the paper?',\n",
    "        'Did the patient-trial matching system positively impact the diversity of subjects participating in the trial?',\n",
    "        'Did the system contribute to enhancing the diversity of subjects participating in the trial?',\n",
    "        'Evaluate the patient-trial matching system described in the paper and assess if it positively impacted the diversity of subjects participating in the trial. Provide a concise textual assessment, detailing whether the system contributed to enhancing the diversity of subjects or not.']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3, Part 2 and Step 4: Retrieving Full Context and Question Answering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The concluding phase of our data extraction process, involves generating answers to our questions through a meticulous recipe. To produce our answers, we amalgamate several crucial components. First, we use the query collection generated above to retrieve relevant text from the Vector Space and form the **Full Context**. Then, we use the **Full Context**, the desired **Output Schema** and a carefully crafted **Prompt** to ask the LLM for an accurate answer to the **original question**. Following this orchestrated assembly, we conduct Question Answering for all queries and archive the responses, utilizing an Excel file as our storage repository.\n",
    "\n",
    "\n",
    "A more detailed explanation of the process can be found below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For each `index` and each **original question** we will go throught the following procedure:\n",
    "\n",
    "- Query the Vector Storage at `index` with each sub-question from the query collection that is associated with the **original question**. This query will retrieve the `K` most relevant text chunks for each sub-question. (A larger `K` value accommodates complex questions, facilitating a comprehensive understanding by yielding more relevant text. In our implementation we set it around 5-20.)\n",
    "\n",
    "- Amalgamate the chunks from the previous step and remove duplicates to form the **Full Context**. The **Full Context** represents the relevant contextual backdrop of `index` that is sufficient and necessary to answer **original question**\n",
    "\n",
    "- Retrieve the specific **Output Schema** corresponding to the question type of **original question** from `schemas` and then populate the **Prompt** template with the **Full Context**, **original question** and **Output Schema** information.\n",
    "\n",
    "- Generate the LLM answer by passing in the populated **Prompt** from the above step and save the answer in the dataframe.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63e8a09",
   "metadata": {},
   "source": [
    "**NOTE: While running this code below for each of the index in the dataframe, when the output of `llm` is `'NO'` we don't extract or process further for it's `llm_name` because we assume that there is no use of LLM in the paper. The code that's responsible for this skipping is**\n",
    "\n",
    "        if (answers.get('llm') is not None) and (answers.get('llm_name') is None):\n",
    "            if answers.get('llm').lower() == 'no':\n",
    "                answers['llm_name'] = '[]'\n",
    "                print('skipping llm_name call..')\n",
    "                continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "44b7f72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_answer(query_collection, index, schemas, k):\n",
    "    \"\"\" Function that asks the LLM all the questions defined in `query_collection` with respect to the document\n",
    "    located at `index` and outputs the result formatted according to the structure defined in `schemas`.\n",
    "\n",
    "    Parameters:\n",
    "    query_collection (dict {str: list[str]}):  Collection of multiple questions mapping each question type to\n",
    "                                               the corresponding sub-questions generated above in Step 3, Part 1\n",
    "    index (int):  The index identifying the document of interest in the dataframe\n",
    "    schemas (dict {str: list[ResponseSchema]}):  Collection mapping each question type to the desired Output Schema\n",
    "    k (int) :  The number of relevant chunks of text to be retrieved for each of the queries.\n",
    "\n",
    "    Returns:\n",
    "    dict {str: str}: A collection mapping each question type to the corresponding answer of the LLM. Additionally maps\n",
    "                     'file_name' to `index`.\n",
    "\n",
    "    An example of a return dictionary:\n",
    "\n",
    "    {'file_name': 5,\n",
    "     'review': 'NO',\n",
    "     'llm': 'Yes',\n",
    "     'llm_name': \"['Watson for Clinical Trial Matching (CTM) cognitive system']\",\n",
    "     'structured_data': 'NO',\n",
    "     'no_of_medical_conditions': '1',\n",
    "     'list_of_medical_conditions': \"['cancer', 'breast cancer']\",\n",
    "     'patient_per_clinical_trial_7a': \"[6.3, 'N/A', 'N/A', 'N/A', 'N/A']\",\n",
    "     'patient_per_clinical_trial': \"[{'Systemic therapy trials enrolling breast cancer patients': 6.3}, {'Breast cancer cohorts of phase I trials within the experimental therapeutics program': 8.1}]\",\n",
    "     'evaluate_patient_trial': 'The paper does not provide specific information about the impact of the patient-trial matching system on the diversity of subjects participating in the trial. It primarily focuses on the increase in breast cancer clinical trial enrollment and the efficiency of the screening process. Therefore, it is difficult to assess whether the system positively impacted the diversity of subjects.'}\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    #Initialize empty directory to save all the answer for each question, for each file\n",
    "    answers = {\"file_name\" : index }\n",
    "\n",
    "    #get the Chroma embeddings of index from the vector storage\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = Chroma(persist_directory= chromadb_folder_path + str(index), embedding_function= embeddings )\n",
    "\n",
    "    #Sample Prompt for our QA\n",
    "    sample = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    Try to be on point and don't make unwanted and unrelated answers.\n",
    "    You will be asked questions which will be related to research paper.\n",
    "    There may be questions that require complex reasoning, in such cases, You should think step-by-step and process your answer to the question\n",
    "    You will be provided context which are from the research paper, the contexts are: {context} {format_instructions}\n",
    "    Question: {question}\n",
    "    Helpful Answer:\"\"\"\n",
    "\n",
    "    template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            SystemMessage(\n",
    "                content=(\n",
    "                    \"You are a helpful assistant that answers question from the provided context which are retrieved from research papers\"\n",
    "                )\n",
    "            ),\n",
    "            HumanMessagePromptTemplate.from_template(sample),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    #initialize our LLM\n",
    "    llm = ChatOpenAI(model_name = openai_model_name)\n",
    "\n",
    "    #We ask GPT to answer our questions, which is saved in query_collection list.\n",
    "    for question_key, question_value in query_collection.items():\n",
    "\n",
    "        # if llm is 'NO' don't run the query for 'llm_name'\n",
    "        if (answers.get('llm') is not None) and (answers.get('llm_name') is None):\n",
    "            if answers.get('llm').lower() == 'no':\n",
    "                answers['llm_name'] = '[]'\n",
    "                print('skipping llm_name call..')\n",
    "                continue\n",
    "\n",
    "        #For each question, retrieve relevant chunks, and ignore the duplicates.\n",
    "        full_context = []\n",
    "        for sub_query in question_value: #question_value contains multiple questions\n",
    "            sub_query_documents = vectorstore.similarity_search(sub_query, k = k)\n",
    "            #filter out the duplicates\n",
    "            for each_docs in sub_query_documents:\n",
    "                if each_docs not in full_context:\n",
    "                    full_context.append(each_docs)\n",
    "\n",
    "        #Choose which schema to use for our questions, question specific schema is chosen\n",
    "        question_schema = schemas[question_key] \n",
    "        output_parser = StructuredOutputParser.from_response_schemas(question_schema)\n",
    "\n",
    "        #format the schema in way that our LLM will understand, this code exactly does this.\n",
    "        format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "        #get the original question\n",
    "        main_question = question_types[question_key]\n",
    "\n",
    "        #Ask question to our LLM, and save answer\n",
    "        answer = llm(template.format_messages(context=full_context, question=main_question, format_instructions=format_instructions ))\n",
    "\n",
    "        print(answer.content)\n",
    "\n",
    "        #save each answer in our dictionary called answers\n",
    "        try:\n",
    "            answers[question_key] = str(output_parser.parse(answer.content)[\"answer\"])\n",
    "        except:\n",
    "            answers[question_key] = str(answer.content)\n",
    "\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727cc6ed",
   "metadata": {},
   "source": [
    "The code below runs the Question Answering task for each rows in our dataframe and saves the results for each question in their respective columns in the pandas dataframe.\n",
    "\n",
    "\n",
    "\n",
    "**NOTE: The code that needs to be changed/experimented with is the `k` value here. If you're using larger model with larger context length like gpt-4-32k then increasing the `k` value to 20-25 yields better results. And I've found that our last question evaluate_patient_trial requires a lot of context to answer the question properly otherwise it will not yield better results whereas other questions with normal chunk size of `k`=10 can also answer quite easily**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4d8d492b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(query_collection, schemas, k=10):\n",
    "    \"\"\" Function performing the Question Answering process for all the datafiles.\n",
    "\n",
    "    Parameters:\n",
    "    query_collection (dict {str: list[str]}):  Collection of multiple questions mapping each question type to\n",
    "                                               the corresponding sub-questions generated above in Step 3, Part 1\n",
    "    schemas (dict {str: list[ResponseSchema]}):  Collection mapping each question type to the desired Output Schema\n",
    "    k (int) :  The number of relevant chunks of text to be retrieved for each of the queries.\n",
    "\n",
    "    Output:\n",
    "\n",
    "    Saves all the results in our pandas dataframe `df` in their specific columns.\n",
    "    \"\"\"\n",
    "\n",
    "    #The code below creates column for each key value in our question_types.\n",
    "    for key,value in question_types.items():\n",
    "        df[key] = None\n",
    "\n",
    "    #Perform question answering and save it in results dictionary\n",
    "    results = dict()\n",
    "    for index, row in df.iterrows():\n",
    "        try:\n",
    "            print(f'---------------------- processing index {index} -------------------------')\n",
    "            results[index]  = question_answer(query_collection, index, schemas, k = k)\n",
    "\n",
    "            #Time sleeping to avoid rate limit error.\n",
    "            time.sleep(20)\n",
    "        except Exception as e:\n",
    "            print('Error!', e)\n",
    "\n",
    "    #save the answers from results dictionary to pandas dataframe, in their specific column\n",
    "    for index,_ in df.iterrows():\n",
    "        result_by_index = results.get(index, '')\n",
    "\n",
    "        #get all the keys from question_types\n",
    "        for key,value in question_types.items():\n",
    "            df.at[index,key] = result_by_index.get(key,'')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04bcbb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------- processing index 1 -------------------------\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"NO\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"YES\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": [\"BERT\", \"Transformer\", \"LSTM\", \"match-LSTM\", \"SPINN\", \"Word-by-word Attention\"]\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"YES\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": [\"Alzheimerâ€™s disease\", \"heart failure\", \"idiopathic pulmonary fibrosis\", \"cancer\", \"diabetes\"]\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"The patient-trial matching system described in the paper, DeepEnroll, positively impacted the diversity of subjects participating in the trial. It outperformed the best state-of-the-art baselines by up to 12.4% in average F1 and 6.8% in PR-AUC, demonstrating improved patient enrollment for trials. Additionally, it showed minimal performance reduction when evaluating patient-trial matching for rare diseases, indicating its effectiveness in recruiting suitable patients for challenging cases. Therefore, DeepEnroll contributed to enhancing the diversity of subjects participating in clinical trials.\"\n",
      "}\n",
      "```\n",
      "---------------------- processing index 2 -------------------------\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"NO\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"YES\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": [\"BERT\", \"GloVe\"]\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"YES\"\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": [\"chronic pain\", \"chronic obstructive pulmonary disease\", \"gastric cancer\", \"lung cancer\", \"glioma\", \"polymyositis\", \"cancer\", \"non small cell lung cancer\", \"metastatic colorectal cancer\", \"colorectal cancer\", \"tumors\", \"solid tumor\", \"chronic demyelinating polyradiculoneuropathy\", \"chronic low back pain\", \"chronic cluster headache\", \"chronic sinusitis with or without nasal polyps\", \"chronic myeloid leukemia\", \"hepatitis c, chronic\", \"chronic severe plaque-type psoriasis\", \"treatment for prevention of chronic migraine\"]\n",
      "}\n",
      "```\n",
      "```json\n",
      "{\n",
      "\t\"answer\": \"The patient-trial matching system described in the paper, COMPOSE, significantly outperformed the best state-of-the-art baselines, achieving 24.3% relatively higher accuracy over the best baselines on patient-trial matching tasks. The system addressed challenges such as multi-granularity medical concept matching, many-to-many relationships between patients and trials, and explicit handling of inclusion and exclusion criteria. However, the paper does not explicitly state if the system positively impacted the diversity of subjects participating in the trial. Therefore, based on the provided context, it is not possible to definitively assess whether the system contributed to enhancing the diversity of subjects.\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "run(query_collection, schemas, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0542352f",
   "metadata": {},
   "source": [
    "# Post-processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5c31195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>FullTextLink</th>\n",
       "      <th>FullText</th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>FullAbstract</th>\n",
       "      <th>PublicationDate</th>\n",
       "      <th>novel</th>\n",
       "      <th>novel_source</th>\n",
       "      <th>AI_ML_source</th>\n",
       "      <th>...</th>\n",
       "      <th>AI_ML</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Resolution_AI_ML</th>\n",
       "      <th>Resolution_NLP</th>\n",
       "      <th>review</th>\n",
       "      <th>llm</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>structured_data</th>\n",
       "      <th>list_of_medical_conditions</th>\n",
       "      <th>evaluate_patient_trial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://arxiv.org/abs/2001.08179</td>\n",
       "      <td>Zhang_2020.pdf</td>\n",
       "      <td>DeepEnroll: patient-trial matching with deep e...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3366423.338...</td>\n",
       "      <td>Clinical trials are essential for drug develop...</td>\n",
       "      <td>2020-04-20 00:00:00</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To address these challenges, we proposed a cro...</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>['BERT', 'Transformer', 'LSTM', 'match-LSTM', ...</td>\n",
       "      <td>YES</td>\n",
       "      <td>['Alzheimerâ€™s disease', 'heart failure', 'idio...</td>\n",
       "      <td>The patient-trial matching system described in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://arxiv.org/abs/2006.08765</td>\n",
       "      <td>Gao_2020.pdf</td>\n",
       "      <td>COMPOSE: Cross-modal pseudo-siamese network fo...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3394486.340...</td>\n",
       "      <td>Clinical trials play important roles in drug d...</td>\n",
       "      <td>2020-06-15 00:00:00</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we proposed CrOss-Modal PseudO-...</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>['BERT', 'GloVe']</td>\n",
       "      <td>YES</td>\n",
       "      <td>['chronic pain', 'chronic obstructive pulmonar...</td>\n",
       "      <td>The patient-trial matching system described in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rank                      FullTextLink        FullText  \\\n",
       "index                                                           \n",
       "1         2  https://arxiv.org/abs/2001.08179  Zhang_2020.pdf   \n",
       "2         3  https://arxiv.org/abs/2006.08765    Gao_2020.pdf   \n",
       "\n",
       "                                                   Title  \\\n",
       "index                                                      \n",
       "1      DeepEnroll: patient-trial matching with deep e...   \n",
       "2      COMPOSE: Cross-modal pseudo-siamese network fo...   \n",
       "\n",
       "                                                    Link  \\\n",
       "index                                                      \n",
       "1      https://dl.acm.org/doi/abs/10.1145/3366423.338...   \n",
       "2      https://dl.acm.org/doi/abs/10.1145/3394486.340...   \n",
       "\n",
       "                                            FullAbstract      PublicationDate  \\\n",
       "index                                                                           \n",
       "1      Clinical trials are essential for drug develop...  2020-04-20 00:00:00   \n",
       "2      Clinical trials play important roles in drug d...  2020-06-15 00:00:00   \n",
       "\n",
       "      novel  novel_source                                       AI_ML_source  \\\n",
       "index                                                                          \n",
       "1       YES           NaN  To address these challenges, we proposed a cro...   \n",
       "2       YES           NaN  In this paper, we proposed CrOss-Modal PseudO-...   \n",
       "\n",
       "       ... AI_ML  NLP Resolution_AI_ML Resolution_NLP review  llm  \\\n",
       "index  ...                                                          \n",
       "1      ...   YES  YES              YES            YES     NO  YES   \n",
       "2      ...   YES  YES              YES            YES     NO  YES   \n",
       "\n",
       "                                                llm_name structured_data  \\\n",
       "index                                                                      \n",
       "1      ['BERT', 'Transformer', 'LSTM', 'match-LSTM', ...             YES   \n",
       "2                                      ['BERT', 'GloVe']             YES   \n",
       "\n",
       "                              list_of_medical_conditions  \\\n",
       "index                                                      \n",
       "1      ['Alzheimerâ€™s disease', 'heart failure', 'idio...   \n",
       "2      ['chronic pain', 'chronic obstructive pulmonar...   \n",
       "\n",
       "                                  evaluate_patient_trial  \n",
       "index                                                     \n",
       "1      The patient-trial matching system described in...  \n",
       "2      The patient-trial matching system described in...  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Removing brackets and quotes\n",
    "\n",
    "The code below removes the brackets and quotes from the **`llm_name`** and **`list_of_medical_conditions`** columns of the dataframe. We do this by extracting what's already saved in those columns, converting the entries to python lists using `ast.literal_eval()` and then convert it to a string joined by ', ' for each value in it.\n",
    "\n",
    "For example:\n",
    "\n",
    "The value that was initially\n",
    "\n",
    "    ['BERT', 'Clinical BERT']\n",
    "\n",
    "will be converted to\n",
    "\n",
    "    BERT, Clinical BERT\n",
    "\n",
    "**NOTE: The value that had empty array [] will now have no value in it, because this array contains no values and we also strip the brackets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffd68fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    \n",
    "    llm_name = row['llm_name']\n",
    "    list_of_medical_conditions = row['list_of_medical_conditions']\n",
    "    \n",
    "    # modification \n",
    "    llm_name = ast.literal_eval(llm_name)\n",
    "    list_of_medical_conditions = ast.literal_eval(list_of_medical_conditions)\n",
    "    \n",
    "    #make a string separated by comma\n",
    "    df.at[index,'llm_name'] = ', '.join(llm_name)\n",
    "    df.at[index, 'list_of_medical_conditions'] = ', '.join(list_of_medical_conditions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90f4f473",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>FullTextLink</th>\n",
       "      <th>FullText</th>\n",
       "      <th>Title</th>\n",
       "      <th>Link</th>\n",
       "      <th>FullAbstract</th>\n",
       "      <th>PublicationDate</th>\n",
       "      <th>novel</th>\n",
       "      <th>novel_source</th>\n",
       "      <th>AI_ML_source</th>\n",
       "      <th>...</th>\n",
       "      <th>AI_ML</th>\n",
       "      <th>NLP</th>\n",
       "      <th>Resolution_AI_ML</th>\n",
       "      <th>Resolution_NLP</th>\n",
       "      <th>review</th>\n",
       "      <th>llm</th>\n",
       "      <th>llm_name</th>\n",
       "      <th>structured_data</th>\n",
       "      <th>list_of_medical_conditions</th>\n",
       "      <th>evaluate_patient_trial</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://arxiv.org/abs/2001.08179</td>\n",
       "      <td>Zhang_2020.pdf</td>\n",
       "      <td>DeepEnroll: patient-trial matching with deep e...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3366423.338...</td>\n",
       "      <td>Clinical trials are essential for drug develop...</td>\n",
       "      <td>2020-04-20 00:00:00</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>To address these challenges, we proposed a cro...</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>BERT, Transformer, LSTM, match-LSTM, SPINN, Wo...</td>\n",
       "      <td>YES</td>\n",
       "      <td>Alzheimerâ€™s disease, heart failure, idiopathic...</td>\n",
       "      <td>The patient-trial matching system described in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://arxiv.org/abs/2006.08765</td>\n",
       "      <td>Gao_2020.pdf</td>\n",
       "      <td>COMPOSE: Cross-modal pseudo-siamese network fo...</td>\n",
       "      <td>https://dl.acm.org/doi/abs/10.1145/3394486.340...</td>\n",
       "      <td>Clinical trials play important roles in drug d...</td>\n",
       "      <td>2020-06-15 00:00:00</td>\n",
       "      <td>YES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper, we proposed CrOss-Modal PseudO-...</td>\n",
       "      <td>...</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>NO</td>\n",
       "      <td>YES</td>\n",
       "      <td>BERT, GloVe</td>\n",
       "      <td>YES</td>\n",
       "      <td>chronic pain, chronic obstructive pulmonary di...</td>\n",
       "      <td>The patient-trial matching system described in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Rank                      FullTextLink        FullText  \\\n",
       "index                                                           \n",
       "1         2  https://arxiv.org/abs/2001.08179  Zhang_2020.pdf   \n",
       "2         3  https://arxiv.org/abs/2006.08765    Gao_2020.pdf   \n",
       "\n",
       "                                                   Title  \\\n",
       "index                                                      \n",
       "1      DeepEnroll: patient-trial matching with deep e...   \n",
       "2      COMPOSE: Cross-modal pseudo-siamese network fo...   \n",
       "\n",
       "                                                    Link  \\\n",
       "index                                                      \n",
       "1      https://dl.acm.org/doi/abs/10.1145/3366423.338...   \n",
       "2      https://dl.acm.org/doi/abs/10.1145/3394486.340...   \n",
       "\n",
       "                                            FullAbstract      PublicationDate  \\\n",
       "index                                                                           \n",
       "1      Clinical trials are essential for drug develop...  2020-04-20 00:00:00   \n",
       "2      Clinical trials play important roles in drug d...  2020-06-15 00:00:00   \n",
       "\n",
       "      novel  novel_source                                       AI_ML_source  \\\n",
       "index                                                                          \n",
       "1       YES           NaN  To address these challenges, we proposed a cro...   \n",
       "2       YES           NaN  In this paper, we proposed CrOss-Modal PseudO-...   \n",
       "\n",
       "       ... AI_ML  NLP Resolution_AI_ML Resolution_NLP review  llm  \\\n",
       "index  ...                                                          \n",
       "1      ...   YES  YES              YES            YES     NO  YES   \n",
       "2      ...   YES  YES              YES            YES     NO  YES   \n",
       "\n",
       "                                                llm_name structured_data  \\\n",
       "index                                                                      \n",
       "1      BERT, Transformer, LSTM, match-LSTM, SPINN, Wo...             YES   \n",
       "2                                            BERT, GloVe             YES   \n",
       "\n",
       "                              list_of_medical_conditions  \\\n",
       "index                                                      \n",
       "1      Alzheimerâ€™s disease, heart failure, idiopathic...   \n",
       "2      chronic pain, chronic obstructive pulmonary di...   \n",
       "\n",
       "                                  evaluate_patient_trial  \n",
       "index                                                     \n",
       "1      The patient-trial matching system described in...  \n",
       "2      The patient-trial matching system described in...  \n",
       "\n",
       "[2 rows x 26 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee0d61a",
   "metadata": {},
   "source": [
    "## Save to excel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we archive the dataframe by saving it as an excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0f219ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('index')\n",
    "df.to_excel('results/FullText_reviewer_GPT4.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test1",
   "language": "python",
   "name": "test1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
